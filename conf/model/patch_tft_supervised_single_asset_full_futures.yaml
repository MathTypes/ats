hidden_size: 20
prediction_length: 48
context_length: 2560
patch_len: 12
stride: 6
d_model: 6
train_batch_size: 1024
eval_batch_size: 512
learning_rate: 0.0095
attn_heads : 4
attn_dropout: 0.1
n_layers: 4
lstm_layers: 4
multitask: True
heads:
  - returns_prediction
  #- position_optimization
returns_prediction:
  #loss_name: MQF2DistributionLoss
  loss_name: "SMAPE"
  target: "close_back"
  logging_metrics: ["SMAPE", "MAE", "RMSE", "MAPE", "MASE"]
position_optimization:
  loss_name: SharpeLoss
  # TODO: figure out how to allow multi loss when same targets are
  # used in different heads.
  target: "close_back_cumsum"
  logging_metrics: []
name: patch_tft_supervised
